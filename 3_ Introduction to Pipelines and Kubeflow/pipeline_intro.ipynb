{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bd737e2",
   "metadata": {},
   "source": [
    "### Step 1: Set the project\n",
    "To set the project - `gcloud config set project <project_name>`\n",
    "\n",
    "To check if the needed project is selected - `echo $GOOGLE_CLOUD_PROJECT`\n",
    "\n",
    "### Step 2: Enabling APIs\n",
    "\n",
    "Type the following commands to enable the APIs:\n",
    "```gcloud services enable compute.googleapis.com \\\n",
    "containerregistry.googleapis.com \\\n",
    " aiplatform.googleapis.com \\\n",
    "cloudbuild.googleapis.com \\\n",
    "cloudfunctions.googleapis.com```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b538f0",
   "metadata": {},
   "source": [
    "In terminal first\n",
    "\n",
    "`sudo apt-get install gcc libpq-dev python3-dev`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff8049f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2ba7bb-dd52-4881-a29b-e21804d25dab",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "USER_FLAG = \"--user\"\n",
    "!pip3 install {USER_FLAG} \"cython<3.0.0\" wheel\n",
    "!pip3 install {USER_FLAG} \"pyyaml==5.4.1\" --no-build-isolation\n",
    "!pip3 install {USER_FLAG} google-cloud-aiplatform \"shapely<2\"\n",
    "!pip3 install {USER_FLAG} kfp==1.8.10 google-cloud-pipeline-components==1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8445031a-11f6-442d-8fae-ff165949d53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restart Kernel after the packages are installed. \n",
    "import os\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a233b63-8bc4-482c-b443-74b57f80c000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the packages for pipelline creation\n",
    "import kfp\n",
    "from kfp.v2 import compiler, dsl\n",
    "from kfp.v2.dsl import component, pipeline, Artifact, ClassificationMetrics, Input, Output, Model, Metrics\n",
    "from typing import NamedTuple\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778d9048-e123-418b-8cee-d24793a86f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To set the project ID\n",
    "import os\n",
    "PROJECT_ID = \"\"\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID is set to : \", PROJECT_ID)\n",
    "if PROJECT_ID == \"\" or PROJECT_ID is None:\n",
    "    PROJECT_ID = \"vertex-ai-gcp-1\"\n",
    "    print(\"Project ID is set manually\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1832cc-d8e3-41b2-a135-98b9355f7f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining bucket to store the artifacts\n",
    "bucket_name_arti=\"gs://\" + PROJECT_ID + \"-pipeline-automl-artifacts\"\n",
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin\n",
    "REGION=\"us-central1\"\n",
    "pipeline_folder = f\"{bucket_name_arti}/pipeline_automl/\"\n",
    "pipeline_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0557baaf-a1c8-440f-81f6-50d5e2378efd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@component(base_image=\"gcr.io/deeplearning-platform-release/tf2-cpu.2-5:latest\",output_component_file=\"model_eval_component.yaml\",\n",
    "    packages_to_install=[\"google-cloud-aiplatform\"],\n",
    ")\n",
    "def image_classification_model_eval_metrics(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    api_endpoint: str,\n",
    "    thresholds_dict_str: str,\n",
    "    model: Input[Artifact],\n",
    "    metrics: Output[Metrics],\n",
    "    metrics_classification: Output[ClassificationMetrics],\n",
    ") -> NamedTuple(\"Outputs\", [(\"dep_decision\", str)]):\n",
    "\n",
    "    import json\n",
    "    import logging\n",
    "\n",
    "    from google.cloud import aiplatform as aip\n",
    "\n",
    "    #  fetch_eval_info function fetches the evaluation information from the trained model.  \n",
    "    def fetch_eval_info(client_name, model_name):\n",
    "        from google.protobuf.json_format import MessageToDict\n",
    "        metrics_list_value = []\n",
    "        metrics_list_string = []\n",
    "        resp = client_name.list_model_evaluations(parent=model_name)\n",
    "\n",
    "        for model_eval in resp:\n",
    "            print(\"trained model evaluation\")\n",
    "            print(\"metric name:\", model_eval.name)\n",
    "            print(\" metrics_schema_uri:\", model_eval.metrics_schema_uri)\n",
    "            model_metrics = MessageToDict(model_eval._pb.metrics)\n",
    "            for metric in model_metrics.keys():logging.info(\"metric: %s, value: %s\", metric, model_metrics[metric])\n",
    "            metrics_list_value.append(model_metrics)\n",
    "            metrics_list_string.append(json.dumps(model_metrics))\n",
    "\n",
    "        return (model_eval.name,metrics_list_value,metrics_list_string)\n",
    "#\n",
    "    def metrics_log_check(metrics_list_value, metrics_classification,thresholds_dict_str):\n",
    "        test_confusion_matrix = metrics_list_value[0][\"confusionMatrix\"]\n",
    "        logging.info(\"rows: %s\", test_confusion_matrix[\"rows\"])\n",
    "\n",
    "        # log the ROC curve\n",
    "        false_pos_rate = []\n",
    "        true_pos_rate = []\n",
    "        thresholds = []\n",
    "        for item in metrics_list_value[0][\"confidenceMetrics\"]:\n",
    "            false_pos_rate.append(item.get(\"falsePositiveRate\", 0.0))\n",
    "            true_pos_rate.append(item.get(\"recall\", 0.0))\n",
    "            thresholds.append(item.get(\"confidenceThreshold\", 0.0))\n",
    "        print(f\"false_pos_rate: {false_pos_rate}\")\n",
    "        print(f\"true_pos_rate: {true_pos_rate}\")\n",
    "        print(f\"thresholds: {thresholds}\")\n",
    "        metrics_classification.log_roc_curve(false_pos_rate, true_pos_rate, thresholds)\n",
    "\n",
    "        # log the confusion matrix\n",
    "        annotations = []\n",
    "        for item in test_confusion_matrix[\"annotationSpecs\"]:\n",
    "            annotations.append(item[\"displayName\"])\n",
    "        logging.info(\"confusion matrix annotations: %s\", annotations)\n",
    "        metrics_classification.log_confusion_matrix(\n",
    "            annotations,\n",
    "            test_confusion_matrix[\"rows\"],\n",
    "        )\n",
    "\n",
    "        # log textual metrics info as well\n",
    "        for metric in metrics_list_value[0].keys():\n",
    "            if metric != \"confidenceMetrics\":\n",
    "                val_string = json.dumps(metrics_list_value[0][metric])\n",
    "                metrics.log_metric(metric, val_string)\n",
    "        \n",
    "        thresholds_dict = json.loads(thresholds_dict_str)\n",
    "        for key, value in thresholds_dict.items():\n",
    "            logging.info(\"key {}, value {}\".format(key, value))\n",
    "            if key in [\"auRoc\", \"auPrc\"]:  # higher is better\n",
    "                if metrics_list_value[0][key] < value:  # if under threshold, don't deploy\n",
    "                    logging.info(\"{} < {}; returning False\".format(metrics_list_value[0][key], value))\n",
    "                    return False\n",
    "        logging.info(\"threshold checks passed.\")\n",
    "        return True\n",
    "    \n",
    "    #Calling all the functions\n",
    "\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    aip.init(project=project)\n",
    "    \n",
    "    # extract the model resource name from the input Model Artifact\n",
    "    model_resource_path = model.metadata[\"resourceName\"]\n",
    "    logging.info(\"model path: %s\", model_resource_path)\n",
    "\n",
    "    client_options = {\"api_endpoint\": api_endpoint}\n",
    "    # Initialize client that will be used to create and send requests.\n",
    "    client = aip.gapic.ModelServiceClient(client_options=client_options)\n",
    "    #To fetch the evaluation information for the specific models\n",
    "    eval_name, metrics_list_value, metrics_str_list = fetch_eval_info(client, model_resource_path)\n",
    "    logging.info(\"got evaluation name: %s\", eval_name)\n",
    "    logging.info(\"got metrics list: %s\", metrics_list_value)\n",
    "    \n",
    "    #To log the confusion matrix.\n",
    "    #log_metrics(metrics_list_value, metrics_classification,thresholds_dict_str)\n",
    "\n",
    "    #thresholds_dict = json.loads(thresholds_dict_str)\n",
    "    deploy = metrics_log_check(metrics_list_value, metrics_classification,thresholds_dict_str)\n",
    "    if deploy:\n",
    "        dep_decision = \"true\"\n",
    "    else:\n",
    "        dep_decision = \"false\"\n",
    "    logging.info(\"deployment decision is %s\", dep_decision)\n",
    "\n",
    "    return (dep_decision,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dcb456-e028-485f-9155-d6a6d76ba99e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DISPLAY_NAME = 'image_boat_classification'\n",
    "@kfp.dsl.pipeline(name=\"image-classification\",pipeline_root=pipeline_folder)\n",
    "\n",
    "#TODO Pipeline\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m99",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m99"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
