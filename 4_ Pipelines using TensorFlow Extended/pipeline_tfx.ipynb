{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbca093-0f39-45c6-b135-036a102cded5",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "USER_FLAG = \"--user\"\n",
    "!pip install {USER_FLAG} --upgrade \"tfx[kfp]<2\"\n",
    "!pip install {USER_FLAG} apache-beam[interactive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bcb506-f8cb-45e3-8866-450bf9da1802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import IPython\n",
    "if not os.getenv(\"\"):\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663d34df-802a-45d1-bfde-80b82459b21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "from tfx import v1 as tfx\n",
    "import kfp\n",
    "print('TensorFlow version:', tf.__version__)\n",
    "print('TFX version: ',tfx.__version__)\n",
    "print('KFP version: ',kfp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4587e61d-4e01-4663-8ddd-a163ed80e354",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID=\"vertex-my\"\n",
    "!gcloud config set project {PROJECT_ID}\n",
    "BUCKET_NAME=\"tfx_pipeline_demo\"\n",
    "NAME_PIPELINE = \"tfx-pipeline\"\n",
    "ROOT_PIPELINE = f'gs://{BUCKET_NAME}/root/{NAME_PIPELINE}'\n",
    "MODULE_FOLDER = f'gs://{BUCKET_NAME}/module/{NAME_PIPELINE}'\n",
    "OUTPUT_MODEL_DIR=f'gs://{BUCKET_NAME}/output_model/{NAME_PIPELINE}'\n",
    "INPUT_DATA_DIR = 'gs://tfx_pipeline_input_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706c5e0c-d098-4763-ade8-0a174386869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "from tensorflow import keras\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "\n",
    "from tfx import v1 as tfx\n",
    "#from tfx.components.statistics_gen.component import StatisticsGen\n",
    "#from tfx.components.schema_gen.component import SchemaGen\n",
    "#from tfx.components.example_gen.csv_example_gen.component import CsvExampleGen\n",
    "from tfx_bsl.public import tfxio\n",
    "from tfx.components.base import executor_spec\n",
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "#from tfx.components.example_validator.component import ExampleValidator\n",
    "#from tfx.components import Transform\n",
    "from tensorflow_metadata.proto.v0 import schema_pb2\n",
    "import os\n",
    "\n",
    "from typing import List\n",
    "#from absl import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33360406-8713-4d4d-869b-83eaeb7e2284",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORM_MODULE_PATH = 'file_transform.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510cbc87-8034-447a-a1be-d40ac611ee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {TRANSFORM_MODULE_PATH}\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "\n",
    "NAMES = ['AF3','F7','F3','FC5','T7','P7','O1','O2','P8','T8','FC6','F4','F8','AF4']\n",
    "LABEL = 'eyeDetection'\n",
    "\n",
    "def preprocessing_fn(raw_inputs):\n",
    "    processed_data = dict()\n",
    "    for items in NAMES:\n",
    "        processed_data[items]=raw_inputs[items]\n",
    "    processed_data[LABEL] = raw_inputs[LABEL]\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df5e8e7-a455-4912-be4c-0b76c16faef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp file_transform.py {MODULE_FOLDER}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9533f00e-8f94-46d9-8164-d12b6e375405",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile trainer.py\n",
    "from typing import List\n",
    "from absl import logging\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "from tensorflow import keras\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "from tfx import v1 as tfx\n",
    "from tfx_bsl.public import tfxio\n",
    "from tensorflow_metadata.proto.v0 import schema_pb2\n",
    "COL_NAMES=['AF3','F7','F3','FC5','T7','P7','O1','O2','P8','T8','FC6','F4','F8','AF4']\n",
    "LABEL=\"eyeDetection\"\n",
    "BATCH_SIZE_TRAIN = 40\n",
    "BATCH_SIZE_EVAL = 20\n",
    "def _input_fn(files,accessor,transform_output,size) -> tf.data.Dataset:\n",
    "    dataset = accessor.tf_dataset_factory(\n",
    "        files,\n",
    "        tfxio.TensorFlowDatasetOptions(batch_size=size),\n",
    "        schema=transform_output.raw_metadata.schema)\n",
    "    tft_layer = transform_output.transform_features_layer()\n",
    "    def apply_transform_fn(raw_input_features):\n",
    "        features_transformed = tft_layer(raw_input_features)\n",
    "        label_transformed = features_transformed.pop(LABEL)\n",
    "        return features_transformed, label_transformed\n",
    "    return dataset.map(apply_transform_fn).repeat()\n",
    "\n",
    "def _get_serve_tf_examples_fn(model, transform_output):\n",
    "    model.tft_layer = transform_output.transform_features_layer()\n",
    "\n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None], dtype=tf.string, name=\"examples\")])\n",
    "    def serve_tf_examples_fn(serialized_tf_sample):\n",
    "        feature_spec_required = {\n",
    "            k: v for k, v in transform_output.raw_feature_spec().items() if k != LABEL\n",
    "        }\n",
    "\n",
    "        parsed_features = tf.io.parse_example(\n",
    "            serialized_tf_sample,\n",
    "            feature_spec_required)\n",
    "        transformed_feat = model.tft_layer(parsed_features)\n",
    "        return model(transformed_feat)\n",
    "    return serve_tf_examples_fn\n",
    "\n",
    "def _make_keras_model() -> tf.keras.Model:\n",
    "\n",
    "    inputs_layer = [keras.layers.Input(shape=(1,), name=n) for n in COL_NAMES]\n",
    "    lay = keras.layers.concatenate(inputs_layer)\n",
    "    lay = keras.layers.Dense(16, activation='relu')(lay)\n",
    "    lay = keras.layers.Dense(4, activation='relu')(lay)\n",
    "    lay = keras.layers.Dense(16, activation='relu')(lay)\n",
    "    lay = keras.layers.Dense(4, activation='relu')(lay)\n",
    "    outputs_layer = keras.layers.Dense(1)(lay)\n",
    "\n",
    "    model_classification = keras.Model(inputs=inputs_layer, outputs=outputs_layer)\n",
    "    opti=keras.optimizers.Adam(1e-2)\n",
    "    los=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    metr=[keras.metrics.BinaryAccuracy()]\n",
    "    model_classification.compile(\n",
    "        optimizer=opti,loss=los,metrics=metr)\n",
    "    return model_classification\n",
    "\n",
    "def run_fn(fn_args: tfx.components.FnArgs):\n",
    "    tf_transform = tft.TFTransformOutput(fn_args.transform_output)\n",
    "    train_samples = _input_fn(\n",
    "        fn_args.train_files,\n",
    "        fn_args.data_accessor,\n",
    "        tf_transform,\n",
    "        size=BATCH_SIZE_TRAIN)\n",
    "    eval_samples = _input_fn(\n",
    "        fn_args.eval_files,\n",
    "        fn_args.data_accessor,\n",
    "        tf_transform,\n",
    "        size=BATCH_SIZE_EVAL)\n",
    "\n",
    "    model_classification = _make_keras_model()\n",
    "    model_classification.fit(\n",
    "        train_samples,\n",
    "        steps_per_epoch=fn_args.train_steps,\n",
    "        validation_data=eval_samples,\n",
    "        validation_steps=fn_args.eval_steps)\n",
    "    sign = {\n",
    "        \"serving_default\": _get_serve_tf_examples_fn(model_classification, tf_transform),\n",
    "    }\n",
    "    model_classification.save(fn_args.serving_model_dir, save_format='tf',signatures=sign)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d019833-3173-4592-9621-63866ad15f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp trainer.py {MODULE_FOLDER}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824c62d9-a861-447a-908c-09c741cfad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_pipeline(pl_name, pipeline_root_folder, data_root,\n",
    "                     module_file_transform, module_file_train, model_dir_save,\n",
    "                     ) -> tfx.dsl.Pipeline:\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec55cadc-f845-480a-8a1d-657291478643",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_file=\"trainer.py\"\n",
    "file_transform=os.path.join(MODULE_FOLDER, TRANSFORM_MODULE_PATH)\n",
    "file_train=os.path.join(MODULE_FOLDER, trainer_file)\n",
    "pl_def_file = NAME_PIPELINE + '.json'\n",
    "\n",
    "pl_runner = tfx.orchestration.experimental.KubeflowV2DagRunner(\n",
    "    config=tfx.orchestration.experimental.KubeflowV2DagRunnerConfig(),\n",
    "    output_filename=pl_def_file)\n",
    "# Following function will write the pipeline definition to PIPELINE_DEFINITION_FILE.\n",
    "_ = pl_runner.run(\n",
    "    _create_pipeline(\n",
    "        pl_name=NAME_PIPELINE,\n",
    "        pipeline_root_folder=ROOT_PIPELINE,\n",
    "        data_root=INPUT_DATA_DIR,\n",
    "        module_file_transform=file_transform,\n",
    "        module_file_train=file_train,\n",
    "        model_dir_save=OUTPUT_MODEL_DIR))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
